
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/ethereum/go-ethereum/swarm/network/common.go (100.0%)</option>
				
				<option value="file1">github.com/ethereum/go-ethereum/swarm/network/discovery.go (63.8%)</option>
				
				<option value="file2">github.com/ethereum/go-ethereum/swarm/network/fetcher.go (90.5%)</option>
				
				<option value="file3">github.com/ethereum/go-ethereum/swarm/network/hive.go (81.2%)</option>
				
				<option value="file4">github.com/ethereum/go-ethereum/swarm/network/kademlia.go (83.5%)</option>
				
				<option value="file5">github.com/ethereum/go-ethereum/swarm/network/protocol.go (84.3%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">// Copyright 2018 The go-ethereum Authors
// This file is part of the go-ethereum library.
//
// The go-ethereum library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// The go-ethereum library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package network

import (
        "fmt"
        "strings"
)

func LogAddrs(nns [][]byte) string <span class="cov8" title="1">{
        var nnsa []string
        for _, nn := range nns </span><span class="cov8" title="1">{
                nnsa = append(nnsa, fmt.Sprintf("%08x", nn[:4]))
        }</span>
        <span class="cov8" title="1">return strings.Join(nnsa, ", ")</span>
}
</pre>
		
		<pre class="file" id="file1" style="display: none">// Copyright 2016 The go-ethereum Authors
// This file is part of the go-ethereum library.
//
// The go-ethereum library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// The go-ethereum library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package network

import (
        "fmt"
        "sync"

        "github.com/ethereum/go-ethereum/swarm/pot"
)

// discovery bzz extension for requesting and relaying node address records

// discPeer wraps BzzPeer and embeds an Overlay connectivity driver
type discPeer struct {
        *BzzPeer
        overlay   Overlay
        sentPeers bool // whether we already sent peer closer to this address
        mtx       sync.RWMutex
        peers     map[string]bool // tracks node records sent to the peer
        depth     uint8           // the proximity order advertised by remote as depth of saturation
}

// NewDiscovery constructs a discovery peer
func newDiscovery(p *BzzPeer, o Overlay) *discPeer <span class="cov8" title="1">{
        d := &amp;discPeer{
                overlay: o,
                BzzPeer: p,
                peers:   make(map[string]bool),
        }
        // record remote as seen so we never send a peer its own record
        d.seen(d)
        return d
}</span>

// HandleMsg is the message handler that delegates incoming messages
func (d *discPeer) HandleMsg(msg interface{}) error <span class="cov8" title="1">{
        switch msg := msg.(type) </span>{

        case *peersMsg:<span class="cov8" title="1">
                return d.handlePeersMsg(msg)</span>

        case *subPeersMsg:<span class="cov0" title="0">
                return d.handleSubPeersMsg(msg)</span>

        default:<span class="cov0" title="0">
                return fmt.Errorf("unknown message type: %T", msg)</span>
        }
}

// NotifyDepth sends a message to all connections if depth of saturation is changed
func NotifyDepth(depth uint8, h Overlay) <span class="cov8" title="1">{
        f := func(val OverlayConn, po int, _ bool) bool </span><span class="cov8" title="1">{
                dp, ok := val.(*discPeer)
                if ok </span><span class="cov8" title="1">{
                        dp.NotifyDepth(depth)
                }</span>
                <span class="cov8" title="1">return true</span>
        }
        <span class="cov8" title="1">h.EachConn(nil, 255, f)</span>
}

// NotifyPeer informs all peers about a newly added node
func NotifyPeer(p OverlayAddr, k Overlay) <span class="cov8" title="1">{
        f := func(val OverlayConn, po int, _ bool) bool </span><span class="cov8" title="1">{
                dp, ok := val.(*discPeer)
                if ok </span><span class="cov8" title="1">{
                        dp.NotifyPeer(p, uint8(po))
                }</span>
                <span class="cov8" title="1">return true</span>
        }
        <span class="cov8" title="1">k.EachConn(p.Address(), 255, f)</span>
}

// NotifyPeer notifies the remote node (recipient) about a peer if
// the peer's PO is within the recipients advertised depth
// OR the peer is closer to the recipient than self
// unless already notified during the connection session
func (d *discPeer) NotifyPeer(a OverlayAddr, po uint8) <span class="cov8" title="1">{
        // immediately return
        if (po &lt; d.getDepth() &amp;&amp; pot.ProxCmp(d.localAddr, d, a) != 1) || d.seen(a) </span><span class="cov8" title="1">{
                return
        }</span>
        // log.Trace(fmt.Sprintf("%08x peer %08x notified of peer %08x", d.localAddr.Over()[:4], d.Address()[:4], a.Address()[:4]))
        <span class="cov8" title="1">resp := &amp;peersMsg{
                Peers: []*BzzAddr{ToAddr(a)},
        }
        go d.Send(resp)</span>
}

// NotifyDepth sends a subPeers Msg to the receiver notifying them about
// a change in the depth of saturation
func (d *discPeer) NotifyDepth(po uint8) <span class="cov8" title="1">{
        // log.Trace(fmt.Sprintf("%08x peer %08x notified of new depth %v", d.localAddr.Over()[:4], d.Address()[:4], po))
        go d.Send(&amp;subPeersMsg{Depth: po})
}</span>

/*
peersMsg is the message to pass peer information
It is always a response to a peersRequestMsg

The encoding of a peer address is identical the devp2p base protocol peers
messages: [IP, Port, NodeID],
Note that a node's FileStore address is not the NodeID but the hash of the NodeID.

TODO:
To mitigate against spurious peers messages, requests should be remembered
and correctness of responses should be checked

If the proxBin of peers in the response is incorrect the sender should be
disconnected
*/

// peersMsg encapsulates an array of peer addresses
// used for communicating about known peers
// relevant for bootstrapping connectivity and updating peersets
type peersMsg struct {
        Peers []*BzzAddr
}

// String pretty prints a peersMsg
func (msg peersMsg) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("%T: %v", msg, msg.Peers)
}</span>

// handlePeersMsg called by the protocol when receiving peerset (for target address)
// list of nodes ([]PeerAddr in peersMsg) is added to the overlay db using the
// Register interface method
func (d *discPeer) handlePeersMsg(msg *peersMsg) error <span class="cov8" title="1">{
        // register all addresses
        if len(msg.Peers) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov8" title="1">for _, a := range msg.Peers </span><span class="cov8" title="1">{
                d.seen(a)
                NotifyPeer(a, d.overlay)
        }</span>
        <span class="cov8" title="1">return d.overlay.Register(toOverlayAddrs(msg.Peers...))</span>
}

// subPeers msg is communicating the depth/sharpness/focus of the overlay table of a peer
type subPeersMsg struct {
        Depth uint8
}

// String returns the pretty printer
func (msg subPeersMsg) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("%T: request peers &gt; PO%02d. ", msg, msg.Depth)
}</span>

func (d *discPeer) handleSubPeersMsg(msg *subPeersMsg) error <span class="cov0" title="0">{
        if !d.sentPeers </span><span class="cov0" title="0">{
                d.setDepth(msg.Depth)
                var peers []*BzzAddr
                d.overlay.EachConn(d.Over(), 255, func(p OverlayConn, po int, isproxbin bool) bool </span><span class="cov0" title="0">{
                        if pob, _ := pof(d, d.localAddr, 0); pob &gt; po </span><span class="cov0" title="0">{
                                return false
                        }</span>
                        <span class="cov0" title="0">if !d.seen(p) </span><span class="cov0" title="0">{
                                peers = append(peers, ToAddr(p.Off()))
                        }</span>
                        <span class="cov0" title="0">return true</span>
                })
                <span class="cov0" title="0">if len(peers) &gt; 0 </span><span class="cov0" title="0">{
                        // log.Debug(fmt.Sprintf("%08x: %v peers sent to %v", d.overlay.BaseAddr(), len(peers), d))
                        go d.Send(&amp;peersMsg{Peers: peers})
                }</span>
        }
        <span class="cov0" title="0">d.sentPeers = true
        return nil</span>
}

// seen takes an Overlay peer and checks if it was sent to a peer already
// if not, marks the peer as sent
func (d *discPeer) seen(p OverlayPeer) bool <span class="cov8" title="1">{
        d.mtx.Lock()
        defer d.mtx.Unlock()
        k := string(p.Address())
        if d.peers[k] </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">d.peers[k] = true
        return false</span>
}

func (d *discPeer) getDepth() uint8 <span class="cov8" title="1">{
        d.mtx.RLock()
        defer d.mtx.RUnlock()
        return d.depth
}</span>
func (d *discPeer) setDepth(depth uint8) <span class="cov0" title="0">{
        d.mtx.Lock()
        defer d.mtx.Unlock()
        d.depth = depth
}</span>
</pre>
		
		<pre class="file" id="file2" style="display: none">// Copyright 2018 The go-ethereum Authors
// This file is part of the go-ethereum library.
//
// The go-ethereum library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// The go-ethereum library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package network

import (
        "context"
        "sync"
        "time"

        "github.com/ethereum/go-ethereum/p2p/discover"

        "github.com/ethereum/go-ethereum/log"
        "github.com/ethereum/go-ethereum/swarm/storage"
)

var searchTimeout = 3000 * time.Millisecond

type RequestFunc func(context.Context, *Request) (*discover.NodeID, chan struct{}, error)

// Fetcher is created when a chunk is not found locally. It starts a request handler loop once and
// keeps it alive until all active requests are completed. This can happen:
//     1. either because the chunk is delivered
//     2. or becuse the requestor cancelled/timed out
// Fetcher self destroys itself after it is completed.
// TODO: cancel all forward requests after termination
type Fetcher struct {
        request   RequestFunc           // request function fetcher calls to issue retrieve request for a chunk
        addr      storage.Address       // the address of the chunk to be fetched
        sourceC   chan *discover.NodeID // channel of sources (peer node id strings)
        skipCheck bool
}

type Request struct {
        Addr        storage.Address  // chunk address
        Source      *discover.NodeID // nodeID of peer to request from (can be nil)
        SkipCheck   bool             // whether to offer the chunk first or deliver directly
        PeersToSkip *sync.Map        // peers not to request chunk from (only makes sense if source is nil)
}

// FetcherFactory is initialised with a request function and can create fetchers
type FetcherFactory struct {
        request   RequestFunc
        skipCheck bool
}

// NewFetcherFactory takes a request function and skip check parameter and creates a FetcherFactory
func NewFetcherFactory(request RequestFunc, skipCheck bool) *FetcherFactory <span class="cov8" title="1">{
        return &amp;FetcherFactory{
                request:   request,
                skipCheck: skipCheck,
        }
}</span>

// New contructs a new Fetcher, for the given source. All peers in peersToSkip are not requested to
// deliver the given chunk. peersToSkip should always contain the peers which are actively requesting
// this chunk, to make sure we don't request back the chunks from them.
// The created Fetcher is started the returned function is its fetch function. This function is used by
// NetStore to fetch a chunk which is not available locally.
func (f *FetcherFactory) New(ctx context.Context, source storage.Address, peersToSkip *sync.Map) storage.FetchFunc <span class="cov8" title="1">{
        fetcher := NewFetcher(source, f.request, f.skipCheck)
        go fetcher.run(ctx, peersToSkip)
        return fetcher.fetch
}</span>

// NewFetcher creates a new Fetcher for the given chunk address using the given request function.
func NewFetcher(addr storage.Address, request RequestFunc, skipCheck bool) *Fetcher <span class="cov8" title="1">{
        return &amp;Fetcher{
                addr:      addr,
                request:   request,
                sourceC:   make(chan *discover.NodeID),
                skipCheck: skipCheck,
        }
}</span>

// fetch is called by NetStore evey time there is a request or offer for a chunk
func (f *Fetcher) fetch(ctx context.Context) <span class="cov8" title="1">{
        // put source/request
        var source *discover.NodeID
        if sourceIF := ctx.Value("source"); sourceIF != nil </span><span class="cov8" title="1">{
                id := discover.MustHexID(sourceIF.(string))
                source = &amp;id
        }</span>
        <span class="cov8" title="1">select </span>{
        case f.sourceC &lt;- source:</span><span class="cov8" title="1">
        case &lt;-ctx.Done():</span><span class="cov8" title="1">
        }
}

// start prepares the Fetcher
// it keeps the Fetcher alive within the lifecycle of the passed context
func (f *Fetcher) run(ctx context.Context, peers *sync.Map) <span class="cov8" title="1">{
        var (
                doRequest bool               // determines if retrieval is initiated in the current iteration
                wait      *time.Timer        // timer for search timeout
                waitC     &lt;-chan time.Time   // timer channel
                sources   []*discover.NodeID // known sources, ie. peers that offered the chunk
                requested bool               // true if the chunk was actually requested
        )
        gone := make(chan *discover.NodeID) // channel to signal that a peer we requested from disconnected

        // loop that keeps the fetching process alive
        // after every request a timer is set. If this goes off we request again from another peer
        // note that the previous request is still alive and has the chance to deliver, so
        // rerequesting extends the search. ie.,
        // if a peer we requested from is gone we issue a new request, so the number of active
        // requests never decreases
        for </span><span class="cov8" title="1">{
                select </span>{

                // accept a request or source.
                case source := &lt;-f.sourceC:<span class="cov8" title="1">
                        if source != nil </span><span class="cov8" title="1">{
                                log.Debug("new source", "peer addr", source, "request addr", f.addr)
                                // 1) the chunk is offered by a syncing peer
                                // add to known sources
                                sources = append(sources, source)
                                // launch a request to the source iff the chunk was requested (not just expected because its offered by a syncing peer)
                                doRequest = requested
                        }</span> else<span class="cov8" title="1"> {
                                log.Debug("new request", "request addr", f.addr)
                                // 2) chunk is requested, set requested flag
                                // launch a request iff none been launched yet
                                doRequest = !requested
                                requested = true
                        }</span>

                        // peer we requested from is gone. fall back to another
                        // and remove the peer from the peers map
                case id := &lt;-gone:<span class="cov0" title="0">
                        log.Debug("peer gone", "peer id", id.String(), "request addr", f.addr)
                        peers.Delete(id.String())
                        doRequest = true</span>

                // search timeout: too much time passed since the last request,
                // extend the search to a new peer if we can find one
                case &lt;-waitC:<span class="cov8" title="1">
                        log.Debug("search timed out: rerequesting", "request addr", f.addr)
                        doRequest = true</span>

                        // all Fetcher context closed, can quit
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        log.Debug("terminate fetcher", "request addr", f.addr)
                        // TODO: send cancelations to all peers left over in peers map (i.e., those we requested from)
                        return</span>
                }

                // need to issue a new request
                <span class="cov8" title="1">if doRequest </span><span class="cov8" title="1">{
                        var err error
                        sources, err = f.doRequest(ctx, gone, peers, sources)
                        if err != nil </span><span class="cov0" title="0">{
                                log.Debug("unable to request", "request addr", f.addr, "err", err)
                        }</span>
                }

                // if wait channel is not set, set it to a timer
                <span class="cov8" title="1">if wait == nil </span><span class="cov8" title="1">{
                        wait = time.NewTimer(searchTimeout)
                        defer wait.Stop()
                        waitC = wait.C
                }</span>
                // reset the timer to go off after searchTimeout
                <span class="cov8" title="1">wait.Reset(searchTimeout)
                doRequest = false</span>
        }
}

// doRequest attempts at finding a peer to request the chunk from
// * first it tries to request explicitly from peers that are known to have offered the chunk
// * if there are no such peers (available) it tries to request it from a peer closest to the chunk address
//   excluding those in the peersToSkip map
// * if no such peer is found an error is returned
//
// if a request is successful,
// * the peer's address is added to the set of peers to skip
// * the peer's address is removed from prospective sources, and
// * a go routine is started that reports on the gone channel if the peer is disconnected (or terminated their streamer)
func (f *Fetcher) doRequest(ctx context.Context, gone chan *discover.NodeID, peersToSkip *sync.Map, sources []*discover.NodeID) ([]*discover.NodeID, error) <span class="cov8" title="1">{
        var i int
        var sourceID *discover.NodeID
        var quit chan struct{}

        req := &amp;Request{
                Addr:        f.addr,
                SkipCheck:   f.skipCheck,
                PeersToSkip: peersToSkip,
        }

        foundSource := false
        // iterate over known sources
        for i = 0; i &lt; len(sources); i++ </span><span class="cov8" title="1">{
                req.Source = sources[i]
                var err error
                sourceID, quit, err = f.request(ctx, req)
                if err == nil </span><span class="cov8" title="1">{
                        // remove the peer from known sources
                        // Note: we can modify the source although we are looping on it, because we break from the loop immediately
                        sources = append(sources[:i], sources[i+1:]...)
                        foundSource = true
                        break</span>
                }
        }

        // if there are no known sources, or none available, we try request from a closest node
        <span class="cov8" title="1">if !foundSource </span><span class="cov8" title="1">{
                req.Source = nil
                var err error
                sourceID, quit, err = f.request(ctx, req)
                if err != nil </span><span class="cov0" title="0">{
                        // if no peers found to request from
                        return sources, err
                }</span>
        }
        // add peer to the set of peers to skip from now
        <span class="cov8" title="1">peersToSkip.Store(sourceID.String(), true)

        // if the quit channel is closed, it indicates that the source peer we requested from
        // disconnected or terminated its streamer
        // here start a go routine that watches this channel and reports the source peer on the gone channel
        // this go routine quits if the fetcher global context is done to prevent process leak
        go func() </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-quit:<span class="cov0" title="0">
                        gone &lt;- sourceID</span>
                case &lt;-ctx.Done():</span><span class="cov8" title="1">
                }
        }()
        <span class="cov8" title="1">return sources, nil</span>
}
</pre>
		
		<pre class="file" id="file3" style="display: none">// Copyright 2016 The go-ethereum Authors
// This file is part of the go-ethereum library.
//
// The go-ethereum library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// The go-ethereum library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package network

import (
        "fmt"
        "sync"
        "time"

        "github.com/ethereum/go-ethereum/common/hexutil"
        "github.com/ethereum/go-ethereum/p2p"
        "github.com/ethereum/go-ethereum/p2p/discover"
        "github.com/ethereum/go-ethereum/swarm/log"
        "github.com/ethereum/go-ethereum/swarm/state"
)

/*
Hive is the logistic manager of the swarm

When the hive is started, a forever loop is launched that
asks the Overlay Topology driver (e.g., generic kademlia nodetable)
to suggest peers to bootstrap connectivity
*/

// Overlay is the interface for kademlia (or other topology drivers)
type Overlay interface {
        // suggest peers to connect to
        SuggestPeer() (OverlayAddr, int, bool)
        // register and deregister peer connections
        On(OverlayConn) (depth uint8, changed bool)
        Off(OverlayConn)
        // register peer addresses
        Register([]OverlayAddr) error
        // iterate over connected peers
        EachConn([]byte, int, func(OverlayConn, int, bool) bool)
        // iterate over known peers (address records)
        EachAddr([]byte, int, func(OverlayAddr, int, bool) bool)
        // pretty print the connectivity
        String() string
        // base Overlay address of the node itself
        BaseAddr() []byte
        // connectivity health check used for testing
        Healthy(*PeerPot) *Health
}

// HiveParams holds the config options to hive
type HiveParams struct {
        Discovery             bool  // if want discovery of not
        PeersBroadcastSetSize uint8 // how many peers to use when relaying
        MaxPeersPerRequest    uint8 // max size for peer address batches
        KeepAliveInterval     time.Duration
}

// NewHiveParams returns hive config with only the
func NewHiveParams() *HiveParams <span class="cov8" title="1">{
        return &amp;HiveParams{
                Discovery:             true,
                PeersBroadcastSetSize: 3,
                MaxPeersPerRequest:    5,
                KeepAliveInterval:     500 * time.Millisecond,
        }
}</span>

// Hive manages network connections of the swarm node
type Hive struct {
        *HiveParams                      // settings
        Overlay                          // the overlay connectiviy driver
        Store       state.Store          // storage interface to save peers across sessions
        addPeer     func(*discover.Node) // server callback to connect to a peer
        // bookkeeping
        lock   sync.Mutex
        ticker *time.Ticker
}

// NewHive constructs a new hive
// HiveParams: config parameters
// Overlay: connectivity driver using a network topology
// StateStore: to save peers across sessions
func NewHive(params *HiveParams, overlay Overlay, store state.Store) *Hive <span class="cov8" title="1">{
        return &amp;Hive{
                HiveParams: params,
                Overlay:    overlay,
                Store:      store,
        }
}</span>

// Start stars the hive, receives p2p.Server only at startup
// server is used to connect to a peer based on its NodeID or enode URL
// these are called on the p2p.Server which runs on the node
func (h *Hive) Start(server *p2p.Server) error <span class="cov8" title="1">{
        log.Info(fmt.Sprintf("%08x hive starting", h.BaseAddr()[:4]))
        // if state store is specified, load peers to prepopulate the overlay address book
        if h.Store != nil </span><span class="cov8" title="1">{
                log.Info("detected an existing store. trying to load peers")
                if err := h.loadPeers(); err != nil </span><span class="cov0" title="0">{
                        log.Error(fmt.Sprintf("%08x hive encoutered an error trying to load peers", h.BaseAddr()[:4]))
                        return err
                }</span>
        }
        // assigns the p2p.Server#AddPeer function to connect to peers
        <span class="cov8" title="1">h.addPeer = server.AddPeer
        // ticker to keep the hive alive
        h.ticker = time.NewTicker(h.KeepAliveInterval)
        // this loop is doing bootstrapping and maintains a healthy table
        go h.connect()
        return nil</span>
}

// Stop terminates the updateloop and saves the peers
func (h *Hive) Stop() error <span class="cov8" title="1">{
        log.Info(fmt.Sprintf("%08x hive stopping, saving peers", h.BaseAddr()[:4]))
        h.ticker.Stop()
        if h.Store != nil </span><span class="cov8" title="1">{
                if err := h.savePeers(); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("could not save peers to persistence store: %v", err)
                }</span>
                <span class="cov8" title="1">if err := h.Store.Close(); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("could not close file handle to persistence store: %v", err)
                }</span>
        }
        <span class="cov8" title="1">log.Info(fmt.Sprintf("%08x hive stopped, dropping peers", h.BaseAddr()[:4]))
        h.EachConn(nil, 255, func(p OverlayConn, _ int, _ bool) bool </span><span class="cov8" title="1">{
                log.Info(fmt.Sprintf("%08x dropping peer %08x", h.BaseAddr()[:4], p.Address()[:4]))
                p.Drop(nil)
                return true
        }</span>)

        <span class="cov8" title="1">log.Info(fmt.Sprintf("%08x all peers dropped", h.BaseAddr()[:4]))
        return nil</span>
}

// connect is a forever loop
// at each iteration, ask the overlay driver to suggest the most preferred peer to connect to
// as well as advertises saturation depth if needed
func (h *Hive) connect() <span class="cov8" title="1">{
        for range h.ticker.C </span><span class="cov8" title="1">{

                addr, depth, changed := h.SuggestPeer()
                if h.Discovery &amp;&amp; changed </span><span class="cov0" title="0">{
                        NotifyDepth(uint8(depth), h)
                }</span>
                <span class="cov8" title="1">if addr == nil </span><span class="cov8" title="1">{
                        continue</span>
                }

                <span class="cov8" title="1">log.Trace(fmt.Sprintf("%08x hive connect() suggested %08x", h.BaseAddr()[:4], addr.Address()[:4]))
                under, err := discover.ParseNode(string(addr.(Addr).Under()))
                if err != nil </span><span class="cov0" title="0">{
                        log.Warn(fmt.Sprintf("%08x unable to connect to bee %08x: invalid node URL: %v", h.BaseAddr()[:4], addr.Address()[:4], err))
                        continue</span>
                }
                <span class="cov8" title="1">log.Trace(fmt.Sprintf("%08x attempt to connect to bee %08x", h.BaseAddr()[:4], addr.Address()[:4]))
                h.addPeer(under)</span>
        }
}

// Run protocol run function
func (h *Hive) Run(p *BzzPeer) error <span class="cov8" title="1">{
        dp := newDiscovery(p, h)
        depth, changed := h.On(dp)
        // if we want discovery, advertise change of depth
        if h.Discovery </span><span class="cov8" title="1">{
                if changed </span><span class="cov8" title="1">{
                        // if depth changed, send to all peers
                        NotifyDepth(depth, h)
                }</span> else<span class="cov8" title="1"> {
                        // otherwise just send depth to new peer
                        dp.NotifyDepth(depth)
                }</span>
        }
        <span class="cov8" title="1">NotifyPeer(p.Off(), h)
        defer h.Off(dp)
        return dp.Run(dp.HandleMsg)</span>
}

// NodeInfo function is used by the p2p.server RPC interface to display
// protocol specific node information
func (h *Hive) NodeInfo() interface{} <span class="cov0" title="0">{
        return h.String()
}</span>

// PeerInfo function is used by the p2p.server RPC interface to display
// protocol specific information any connected peer referred to by their NodeID
func (h *Hive) PeerInfo(id discover.NodeID) interface{} <span class="cov0" title="0">{
        addr := NewAddrFromNodeID(id)
        return struct {
                OAddr hexutil.Bytes
                UAddr hexutil.Bytes
        }{
                OAddr: addr.OAddr,
                UAddr: addr.UAddr,
        }
}</span>

// ToAddr returns the serialisable version of u
func ToAddr(pa OverlayPeer) *BzzAddr <span class="cov8" title="1">{
        if addr, ok := pa.(*BzzAddr); ok </span><span class="cov8" title="1">{
                return addr
        }</span>
        <span class="cov8" title="1">if p, ok := pa.(*discPeer); ok </span><span class="cov8" title="1">{
                return p.BzzAddr
        }</span>
        <span class="cov0" title="0">return pa.(*BzzPeer).BzzAddr</span>
}

// loadPeers, savePeer implement persistence callback/
func (h *Hive) loadPeers() error <span class="cov8" title="1">{
        var as []*BzzAddr
        err := h.Store.Get("peers", &amp;as)
        if err != nil </span><span class="cov8" title="1">{
                if err == state.ErrNotFound </span><span class="cov8" title="1">{
                        log.Info(fmt.Sprintf("hive %08x: no persisted peers found", h.BaseAddr()[:4]))
                        return nil
                }</span>
                <span class="cov0" title="0">return err</span>
        }
        <span class="cov8" title="1">log.Info(fmt.Sprintf("hive %08x: peers loaded", h.BaseAddr()[:4]))

        return h.Register(toOverlayAddrs(as...))</span>
}

// toOverlayAddrs transforms an array of BzzAddr to OverlayAddr
func toOverlayAddrs(as ...*BzzAddr) (oas []OverlayAddr) <span class="cov8" title="1">{
        for _, a := range as </span><span class="cov8" title="1">{
                oas = append(oas, OverlayAddr(a))
        }</span>
        <span class="cov8" title="1">return</span>
}

// savePeers, savePeer implement persistence callback/
func (h *Hive) savePeers() error <span class="cov8" title="1">{
        var peers []*BzzAddr
        h.Overlay.EachAddr(nil, 256, func(pa OverlayAddr, i int, _ bool) bool </span><span class="cov8" title="1">{
                if pa == nil </span><span class="cov0" title="0">{
                        log.Warn(fmt.Sprintf("empty addr: %v", i))
                        return true
                }</span>
                <span class="cov8" title="1">apa := ToAddr(pa)
                log.Trace("saving peer", "peer", apa)
                peers = append(peers, apa)
                return true</span>
        })
        <span class="cov8" title="1">if err := h.Store.Put("peers", peers); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("could not save peers: %v", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">// Copyright 2017 The go-ethereum Authors
// This file is part of the go-ethereum library.
//
// The go-ethereum library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// The go-ethereum library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package network

import (
        "bytes"
        "fmt"
        "math/rand"
        "strings"
        "sync"
        "time"

        "github.com/ethereum/go-ethereum/common"
        "github.com/ethereum/go-ethereum/swarm/log"
        "github.com/ethereum/go-ethereum/swarm/pot"
)

/*

Taking the proximity order relative to a fix point x classifies the points in
the space (n byte long byte sequences) into bins. Items in each are at
most half as distant from x as items in the previous bin. Given a sample of
uniformly distributed items (a hash function over arbitrary sequence) the
proximity scale maps onto series of subsets with cardinalities on a negative
exponential scale.

It also has the property that any two item belonging to the same bin are at
most half as distant from each other as they are from x.

If we think of random sample of items in the bins as connections in a network of
interconnected nodes then relative proximity can serve as the basis for local
decisions for graph traversal where the task is to find a route between two
points. Since in every hop, the finite distance halves, there is
a guaranteed constant maximum limit on the number of hops needed to reach one
node from the other.
*/

var pof = pot.DefaultPof(256)

// KadParams holds the config params for Kademlia
type KadParams struct {
        // adjustable parameters
        MaxProxDisplay int   // number of rows the table shows
        MinProxBinSize int   // nearest neighbour core minimum cardinality
        MinBinSize     int   // minimum number of peers in a row
        MaxBinSize     int   // maximum number of peers in a row before pruning
        RetryInterval  int64 // initial interval before a peer is first redialed
        RetryExponent  int   // exponent to multiply retry intervals with
        MaxRetries     int   // maximum number of redial attempts
        // function to sanction or prevent suggesting a peer
        Reachable func(OverlayAddr) bool
}

// NewKadParams returns a params struct with default values
func NewKadParams() *KadParams <span class="cov8" title="1">{
        return &amp;KadParams{
                MaxProxDisplay: 16,
                MinProxBinSize: 2,
                MinBinSize:     2,
                MaxBinSize:     4,
                RetryInterval:  4200000000, // 4.2 sec
                MaxRetries:     42,
                RetryExponent:  2,
        }
}</span>

// Kademlia is a table of live peers and a db of known peers (node records)
type Kademlia struct {
        lock       sync.RWMutex
        *KadParams          // Kademlia configuration parameters
        base       []byte   // immutable baseaddress of the table
        addrs      *pot.Pot // pots container for known peer addresses
        conns      *pot.Pot // pots container for live peer connections
        depth      uint8    // stores the last current depth of saturation
        nDepth     int      // stores the last neighbourhood depth
        nDepthC    chan int // returned by DepthC function to signal neighbourhood depth change
        addrCountC chan int // returned by AddrCountC function to signal peer count change
}

// NewKademlia creates a Kademlia table for base address addr
// with parameters as in params
// if params is nil, it uses default values
func NewKademlia(addr []byte, params *KadParams) *Kademlia <span class="cov8" title="1">{
        if params == nil </span><span class="cov0" title="0">{
                params = NewKadParams()
        }</span>
        <span class="cov8" title="1">return &amp;Kademlia{
                base:      addr,
                KadParams: params,
                addrs:     pot.NewPot(nil, 0),
                conns:     pot.NewPot(nil, 0),
        }</span>
}

// OverlayPeer interface captures the common aspect of view of a peer from the Overlay
// topology driver
type OverlayPeer interface {
        Address() []byte
}

// OverlayConn represents a connected peer
type OverlayConn interface {
        OverlayPeer
        Drop(error)       // call to indicate a peer should be expunged
        Off() OverlayAddr // call to return a persitent OverlayAddr
}

// OverlayAddr represents a kademlia peer record
type OverlayAddr interface {
        OverlayPeer
        Update(OverlayAddr) OverlayAddr // returns the updated version of the original
}

// entry represents a Kademlia table entry (an extension of OverlayPeer)
type entry struct {
        OverlayPeer
        seenAt  time.Time
        retries int
}

// newEntry creates a kademlia peer from an OverlayPeer interface
func newEntry(p OverlayPeer) *entry <span class="cov8" title="1">{
        return &amp;entry{
                OverlayPeer: p,
                seenAt:      time.Now(),
        }
}</span>

// Bin is the binary (bitvector) serialisation of the entry address
func (e *entry) Bin() string <span class="cov0" title="0">{
        return pot.ToBin(e.addr().Address())
}</span>

// Label is a short tag for the entry for debug
func Label(e *entry) string <span class="cov8" title="1">{
        return fmt.Sprintf("%s (%d)", e.Hex()[:4], e.retries)
}</span>

// Hex is the hexadecimal serialisation of the entry address
func (e *entry) Hex() string <span class="cov8" title="1">{
        return fmt.Sprintf("%x", e.addr().Address())
}</span>

// String is the short tag for the entry
func (e *entry) String() string <span class="cov8" title="1">{
        return fmt.Sprintf("%s (%d)", e.Hex()[:8], e.retries)
}</span>

// addr returns the kad peer record (OverlayAddr) corresponding to the entry
func (e *entry) addr() OverlayAddr <span class="cov8" title="1">{
        a, _ := e.OverlayPeer.(OverlayAddr)
        return a
}</span>

// conn returns the connected peer (OverlayPeer) corresponding to the entry
func (e *entry) conn() OverlayConn <span class="cov8" title="1">{
        c, _ := e.OverlayPeer.(OverlayConn)
        return c
}</span>

// Register enters each OverlayAddr as kademlia peer record into the
// database of known peer addresses
func (k *Kademlia) Register(peers []OverlayAddr) error <span class="cov8" title="1">{
        k.lock.Lock()
        defer k.lock.Unlock()
        var known, size int
        for _, p := range peers </span><span class="cov8" title="1">{
                // error if self received, peer should know better
                // and should be punished for this
                if bytes.Equal(p.Address(), k.base) </span><span class="cov0" title="0">{
                        return fmt.Errorf("add peers: %x is self", k.base)
                }</span>
                <span class="cov8" title="1">var found bool
                k.addrs, _, found, _ = pot.Swap(k.addrs, p, pof, func(v pot.Val) pot.Val </span><span class="cov8" title="1">{
                        // if not found
                        if v == nil </span><span class="cov8" title="1">{
                                // insert new offline peer into conns
                                return newEntry(p)
                        }</span>
                        // found among known peers, do nothing
                        <span class="cov8" title="1">return v</span>
                })
                <span class="cov8" title="1">if found </span><span class="cov8" title="1">{
                        known++
                }</span>
                <span class="cov8" title="1">size++</span>
        }
        // send new address count value only if there are new addresses
        <span class="cov8" title="1">if k.addrCountC != nil &amp;&amp; size-known &gt; 0 </span><span class="cov0" title="0">{
                k.addrCountC &lt;- k.addrs.Size()
        }</span>
        // log.Trace(fmt.Sprintf("%x registered %v peers, %v known, total: %v", k.BaseAddr()[:4], size, known, k.addrs.Size()))

        <span class="cov8" title="1">k.sendNeighbourhoodDepthChange()
        return nil</span>
}

// SuggestPeer returns a known peer for the lowest proximity bin for the
// lowest bincount below depth
// naturally if there is an empty row it returns a peer for that
func (k *Kademlia) SuggestPeer() (a OverlayAddr, o int, want bool) <span class="cov8" title="1">{
        k.lock.Lock()
        defer k.lock.Unlock()
        minsize := k.MinBinSize
        depth := k.neighbourhoodDepth()
        // if there is a callable neighbour within the current proxBin, connect
        // this makes sure nearest neighbour set is fully connected
        var ppo int
        k.addrs.EachNeighbour(k.base, pof, func(val pot.Val, po int) bool </span><span class="cov8" title="1">{
                if po &lt; depth </span><span class="cov8" title="1">{
                        return false
                }</span>
                <span class="cov8" title="1">a = k.callable(val)
                ppo = po
                return a == nil</span>
        })
        <span class="cov8" title="1">if a != nil </span><span class="cov8" title="1">{
                log.Trace(fmt.Sprintf("%08x candidate nearest neighbour found: %v (%v)", k.BaseAddr()[:4], a, ppo))
                return a, 0, false
        }</span>
        // log.Trace(fmt.Sprintf("%08x no candidate nearest neighbours to connect to (Depth: %v, minProxSize: %v) %#v", k.BaseAddr()[:4], depth, k.MinProxBinSize, a))

        <span class="cov8" title="1">var bpo []int
        prev := -1
        k.conns.EachBin(k.base, pof, 0, func(po, size int, f func(func(val pot.Val, i int) bool) bool) bool </span><span class="cov8" title="1">{
                prev++
                for ; prev &lt; po; prev++ </span><span class="cov8" title="1">{
                        bpo = append(bpo, prev)
                        minsize = 0
                }</span>
                <span class="cov8" title="1">if size &lt; minsize </span><span class="cov8" title="1">{
                        bpo = append(bpo, po)
                        minsize = size
                }</span>
                <span class="cov8" title="1">return size &gt; 0 &amp;&amp; po &lt; depth</span>
        })
        // all buckets are full, ie., minsize == k.MinBinSize
        <span class="cov8" title="1">if len(bpo) == 0 </span><span class="cov8" title="1">{
                // log.Debug(fmt.Sprintf("%08x: all bins saturated", k.BaseAddr()[:4]))
                return nil, 0, false
        }</span>
        // as long as we got candidate peers to connect to
        // dont ask for new peers (want = false)
        // try to select a candidate peer
        // find the first callable peer
        <span class="cov8" title="1">nxt := bpo[0]
        k.addrs.EachBin(k.base, pof, nxt, func(po, _ int, f func(func(pot.Val, int) bool) bool) bool </span><span class="cov8" title="1">{
                // for each bin (up until depth) we find callable candidate peers
                if po &gt;= depth </span><span class="cov8" title="1">{
                        return false
                }</span>
                <span class="cov8" title="1">return f(func(val pot.Val, _ int) bool </span><span class="cov8" title="1">{
                        a = k.callable(val)
                        return a == nil
                }</span>)
        })
        // found a candidate
        <span class="cov8" title="1">if a != nil </span><span class="cov8" title="1">{
                return a, 0, false
        }</span>
        // no candidate peer found, request for the short bin
        <span class="cov8" title="1">var changed bool
        if uint8(nxt) &lt; k.depth </span><span class="cov8" title="1">{
                k.depth = uint8(nxt)
                changed = true
        }</span>
        <span class="cov8" title="1">return a, nxt, changed</span>
}

// On inserts the peer as a kademlia peer into the live peers
func (k *Kademlia) On(p OverlayConn) (uint8, bool) <span class="cov8" title="1">{
        k.lock.Lock()
        defer k.lock.Unlock()
        e := newEntry(p)
        var ins bool
        k.conns, _, _, _ = pot.Swap(k.conns, p, pof, func(v pot.Val) pot.Val </span><span class="cov8" title="1">{
                // if not found live
                if v == nil </span><span class="cov8" title="1">{
                        ins = true
                        // insert new online peer into conns
                        return e
                }</span>
                // found among live peers, do nothing
                <span class="cov8" title="1">return v</span>
        })
        <span class="cov8" title="1">if ins </span><span class="cov8" title="1">{
                // insert new online peer into addrs
                k.addrs, _, _, _ = pot.Swap(k.addrs, p, pof, func(v pot.Val) pot.Val </span><span class="cov8" title="1">{
                        return e
                }</span>)
                // send new address count value only if the peer is inserted
                <span class="cov8" title="1">if k.addrCountC != nil </span><span class="cov0" title="0">{
                        k.addrCountC &lt;- k.addrs.Size()
                }</span>
        }
        <span class="cov8" title="1">log.Trace(k.string())
        // calculate if depth of saturation changed
        depth := uint8(k.saturation(k.MinBinSize))
        var changed bool
        if depth != k.depth </span><span class="cov8" title="1">{
                changed = true
                k.depth = depth
        }</span>
        <span class="cov8" title="1">k.sendNeighbourhoodDepthChange()
        return k.depth, changed</span>
}

// NeighbourhoodDepthC returns the channel that sends a new kademlia
// neighbourhood depth on each change.
// Not receiving from the returned channel will block On function
// when the neighbourhood depth is changed.
func (k *Kademlia) NeighbourhoodDepthC() &lt;-chan int <span class="cov0" title="0">{
        if k.nDepthC == nil </span><span class="cov0" title="0">{
                k.nDepthC = make(chan int)
        }</span>
        <span class="cov0" title="0">return k.nDepthC</span>
}

// sendNeighbourhoodDepthChange sends new neighbourhood depth to k.nDepth channel
// if it is initialized.
func (k *Kademlia) sendNeighbourhoodDepthChange() <span class="cov8" title="1">{
        // nDepthC is initialized when NeighbourhoodDepthC is called and returned by it.
        // It provides signaling of neighbourhood depth change.
        // This part of the code is sending new neighbourhood depth to nDepthC if that condition is met.
        if k.nDepthC != nil </span><span class="cov0" title="0">{
                nDepth := k.neighbourhoodDepth()
                if nDepth != k.nDepth </span><span class="cov0" title="0">{
                        k.nDepth = nDepth
                        k.nDepthC &lt;- nDepth
                }</span>
        }
}

// AddrCountC returns the channel that sends a new
// address count value on each change.
// Not receiving from the returned channel will block Register function
// when address count value changes.
func (k *Kademlia) AddrCountC() &lt;-chan int <span class="cov0" title="0">{
        if k.addrCountC == nil </span><span class="cov0" title="0">{
                k.addrCountC = make(chan int)
        }</span>
        <span class="cov0" title="0">return k.addrCountC</span>
}

// Off removes a peer from among live peers
func (k *Kademlia) Off(p OverlayConn) <span class="cov8" title="1">{
        k.lock.Lock()
        defer k.lock.Unlock()
        var del bool
        k.addrs, _, _, _ = pot.Swap(k.addrs, p, pof, func(v pot.Val) pot.Val </span><span class="cov8" title="1">{
                // v cannot be nil, must check otherwise we overwrite entry
                if v == nil </span><span class="cov0" title="0">{
                        panic(fmt.Sprintf("connected peer not found %v", p))</span>
                }
                <span class="cov8" title="1">del = true
                return newEntry(p.Off())</span>
        })

        <span class="cov8" title="1">if del </span><span class="cov8" title="1">{
                k.conns, _, _, _ = pot.Swap(k.conns, p, pof, func(_ pot.Val) pot.Val </span><span class="cov8" title="1">{
                        // v cannot be nil, but no need to check
                        return nil
                }</span>)
                // send new address count value only if the peer is deleted
                <span class="cov8" title="1">if k.addrCountC != nil </span><span class="cov0" title="0">{
                        k.addrCountC &lt;- k.addrs.Size()
                }</span>
                <span class="cov8" title="1">k.sendNeighbourhoodDepthChange()</span>
        }
}

func (k *Kademlia) EachBin(base []byte, pof pot.Pof, o int, eachBinFunc func(conn OverlayConn, po int) bool) <span class="cov0" title="0">{
        k.lock.RLock()
        defer k.lock.RUnlock()

        var startPo int
        var endPo int
        kadDepth := k.neighbourhoodDepth()

        k.conns.EachBin(base, pof, o, func(po, size int, f func(func(val pot.Val, i int) bool) bool) bool </span><span class="cov0" title="0">{
                if startPo &gt; 0 &amp;&amp; endPo != k.MaxProxDisplay </span><span class="cov0" title="0">{
                        startPo = endPo + 1
                }</span>
                <span class="cov0" title="0">if po &lt; kadDepth </span><span class="cov0" title="0">{
                        endPo = po
                }</span> else<span class="cov0" title="0"> {
                        endPo = k.MaxProxDisplay
                }</span>

                <span class="cov0" title="0">for bin := startPo; bin &lt;= endPo; bin++ </span><span class="cov0" title="0">{
                        f(func(val pot.Val, _ int) bool </span><span class="cov0" title="0">{
                                return eachBinFunc(val.(*entry).conn(), bin)
                        }</span>)
                }
                <span class="cov0" title="0">return true</span>
        })
}

// EachConn is an iterator with args (base, po, f) applies f to each live peer
// that has proximity order po or less as measured from the base
// if base is nil, kademlia base address is used
func (k *Kademlia) EachConn(base []byte, o int, f func(OverlayConn, int, bool) bool) <span class="cov8" title="1">{
        k.lock.RLock()
        defer k.lock.RUnlock()
        k.eachConn(base, o, f)
}</span>

func (k *Kademlia) eachConn(base []byte, o int, f func(OverlayConn, int, bool) bool) <span class="cov8" title="1">{
        if len(base) == 0 </span><span class="cov8" title="1">{
                base = k.base
        }</span>
        <span class="cov8" title="1">depth := k.neighbourhoodDepth()
        k.conns.EachNeighbour(base, pof, func(val pot.Val, po int) bool </span><span class="cov8" title="1">{
                if po &gt; o </span><span class="cov8" title="1">{
                        return true
                }</span>
                <span class="cov8" title="1">return f(val.(*entry).conn(), po, po &gt;= depth)</span>
        })
}

// EachAddr called with (base, po, f) is an iterator applying f to each known peer
// that has proximity order po or less as measured from the base
// if base is nil, kademlia base address is used
func (k *Kademlia) EachAddr(base []byte, o int, f func(OverlayAddr, int, bool) bool) <span class="cov8" title="1">{
        k.lock.RLock()
        defer k.lock.RUnlock()
        k.eachAddr(base, o, f)
}</span>

func (k *Kademlia) eachAddr(base []byte, o int, f func(OverlayAddr, int, bool) bool) <span class="cov8" title="1">{
        if len(base) == 0 </span><span class="cov8" title="1">{
                base = k.base
        }</span>
        <span class="cov8" title="1">depth := k.neighbourhoodDepth()
        k.addrs.EachNeighbour(base, pof, func(val pot.Val, po int) bool </span><span class="cov8" title="1">{
                if po &gt; o </span><span class="cov8" title="1">{
                        return true
                }</span>
                <span class="cov8" title="1">return f(val.(*entry).addr(), po, po &gt;= depth)</span>
        })
}

// neighbourhoodDepth returns the proximity order that defines the distance of
// the nearest neighbour set with cardinality &gt;= MinProxBinSize
// if there is altogether less than MinProxBinSize peers it returns 0
// caller must hold the lock
func (k *Kademlia) neighbourhoodDepth() (depth int) <span class="cov8" title="1">{
        if k.conns.Size() &lt; k.MinProxBinSize </span><span class="cov8" title="1">{
                return 0
        }</span>
        <span class="cov8" title="1">var size int
        f := func(v pot.Val, i int) bool </span><span class="cov8" title="1">{
                size++
                depth = i
                return size &lt; k.MinProxBinSize
        }</span>
        <span class="cov8" title="1">k.conns.EachNeighbour(k.base, pof, f)
        return depth</span>
}

// callable when called with val,
func (k *Kademlia) callable(val pot.Val) OverlayAddr <span class="cov8" title="1">{
        e := val.(*entry)
        // not callable if peer is live or exceeded maxRetries
        if e.conn() != nil || e.retries &gt; k.MaxRetries </span><span class="cov8" title="1">{
                return nil
        }</span>
        // calculate the allowed number of retries based on time lapsed since last seen
        <span class="cov8" title="1">timeAgo := int64(time.Since(e.seenAt))
        div := int64(k.RetryExponent)
        div += (150000 - rand.Int63n(300000)) * div / 1000000
        var retries int
        for delta := timeAgo; delta &gt; k.RetryInterval; delta /= div </span><span class="cov0" title="0">{
                retries++
        }</span>
        // this is never called concurrently, so safe to increment
        // peer can be retried again
        <span class="cov8" title="1">if retries &lt; e.retries </span><span class="cov8" title="1">{
                log.Trace(fmt.Sprintf("%08x: %v long time since last try (at %v) needed before retry %v, wait only warrants %v", k.BaseAddr()[:4], e, timeAgo, e.retries, retries))
                return nil
        }</span>
        // function to sanction or prevent suggesting a peer
        <span class="cov8" title="1">if k.Reachable != nil &amp;&amp; !k.Reachable(e.addr()) </span><span class="cov0" title="0">{
                log.Trace(fmt.Sprintf("%08x: peer %v is temporarily not callable", k.BaseAddr()[:4], e))
                return nil
        }</span>
        <span class="cov8" title="1">e.retries++
        log.Trace(fmt.Sprintf("%08x: peer %v is callable", k.BaseAddr()[:4], e))

        return e.addr()</span>
}

// BaseAddr return the kademlia base address
func (k *Kademlia) BaseAddr() []byte <span class="cov8" title="1">{
        return k.base
}</span>

// String returns kademlia table + kaddb table displayed with ascii
func (k *Kademlia) String() string <span class="cov8" title="1">{
        k.lock.RLock()
        defer k.lock.RUnlock()
        return k.string()
}</span>

// String returns kademlia table + kaddb table displayed with ascii
func (k *Kademlia) string() string <span class="cov8" title="1">{
        wsrow := "                          "
        var rows []string

        rows = append(rows, "=========================================================================")
        rows = append(rows, fmt.Sprintf("%v KMLI hive: queen's address: %x", time.Now().UTC().Format(time.UnixDate), k.BaseAddr()[:3]))
        rows = append(rows, fmt.Sprintf("population: %d (%d), MinProxBinSize: %d, MinBinSize: %d, MaxBinSize: %d", k.conns.Size(), k.addrs.Size(), k.MinProxBinSize, k.MinBinSize, k.MaxBinSize))

        liverows := make([]string, k.MaxProxDisplay)
        peersrows := make([]string, k.MaxProxDisplay)

        depth := k.neighbourhoodDepth()
        rest := k.conns.Size()
        k.conns.EachBin(k.base, pof, 0, func(po, size int, f func(func(val pot.Val, i int) bool) bool) bool </span><span class="cov8" title="1">{
                var rowlen int
                if po &gt;= k.MaxProxDisplay </span><span class="cov0" title="0">{
                        po = k.MaxProxDisplay - 1
                }</span>
                <span class="cov8" title="1">row := []string{fmt.Sprintf("%2d", size)}
                rest -= size
                f(func(val pot.Val, vpo int) bool </span><span class="cov8" title="1">{
                        e := val.(*entry)
                        row = append(row, fmt.Sprintf("%x", e.Address()[:2]))
                        rowlen++
                        return rowlen &lt; 4
                }</span>)
                <span class="cov8" title="1">r := strings.Join(row, " ")
                r = r + wsrow
                liverows[po] = r[:31]
                return true</span>
        })

        <span class="cov8" title="1">k.addrs.EachBin(k.base, pof, 0, func(po, size int, f func(func(val pot.Val, i int) bool) bool) bool </span><span class="cov8" title="1">{
                var rowlen int
                if po &gt;= k.MaxProxDisplay </span><span class="cov0" title="0">{
                        po = k.MaxProxDisplay - 1
                }</span>
                <span class="cov8" title="1">if size &lt; 0 </span><span class="cov0" title="0">{
                        panic("wtf")</span>
                }
                <span class="cov8" title="1">row := []string{fmt.Sprintf("%2d", size)}
                // we are displaying live peers too
                f(func(val pot.Val, vpo int) bool </span><span class="cov8" title="1">{
                        e := val.(*entry)
                        row = append(row, Label(e))
                        rowlen++
                        return rowlen &lt; 4
                }</span>)
                <span class="cov8" title="1">peersrows[po] = strings.Join(row, " ")
                return true</span>
        })

        <span class="cov8" title="1">for i := 0; i &lt; k.MaxProxDisplay; i++ </span><span class="cov8" title="1">{
                if i == depth </span><span class="cov8" title="1">{
                        rows = append(rows, fmt.Sprintf("============ DEPTH: %d ==========================================", i))
                }</span>
                <span class="cov8" title="1">left := liverows[i]
                right := peersrows[i]
                if len(left) == 0 </span><span class="cov8" title="1">{
                        left = " 0                             "
                }</span>
                <span class="cov8" title="1">if len(right) == 0 </span><span class="cov8" title="1">{
                        right = " 0"
                }</span>
                <span class="cov8" title="1">rows = append(rows, fmt.Sprintf("%03d %v | %v", i, left, right))</span>
        }
        <span class="cov8" title="1">rows = append(rows, "=========================================================================")
        return "\n" + strings.Join(rows, "\n")</span>
}

// PeerPot keeps info about expected nearest neighbours and empty bins
// used for testing only
type PeerPot struct {
        NNSet     [][]byte
        EmptyBins []int
}

// NewPeerPotMap creates a map of pot record of OverlayAddr with keys
// as hexadecimal representations of the address.
func NewPeerPotMap(kadMinProxSize int, addrs [][]byte) map[string]*PeerPot <span class="cov8" title="1">{
        // create a table of all nodes for health check
        np := pot.NewPot(nil, 0)
        for _, addr := range addrs </span><span class="cov8" title="1">{
                np, _, _ = pot.Add(np, addr, pof)
        }</span>
        <span class="cov8" title="1">ppmap := make(map[string]*PeerPot)

        for i, a := range addrs </span><span class="cov8" title="1">{
                pl := 256
                prev := 256
                var emptyBins []int
                var nns [][]byte
                np.EachNeighbour(addrs[i], pof, func(val pot.Val, po int) bool </span><span class="cov8" title="1">{
                        a := val.([]byte)
                        if po == 256 </span><span class="cov8" title="1">{
                                return true
                        }</span>
                        <span class="cov8" title="1">if pl == 256 || pl == po </span><span class="cov8" title="1">{
                                nns = append(nns, a)
                        }</span>
                        <span class="cov8" title="1">if pl == 256 &amp;&amp; len(nns) &gt;= kadMinProxSize </span><span class="cov8" title="1">{
                                pl = po
                                prev = po
                        }</span>
                        <span class="cov8" title="1">if prev &lt; pl </span><span class="cov8" title="1">{
                                for j := prev; j &gt; po; j-- </span><span class="cov8" title="1">{
                                        emptyBins = append(emptyBins, j)
                                }</span>
                        }
                        <span class="cov8" title="1">prev = po - 1
                        return true</span>
                })
                <span class="cov8" title="1">for j := prev; j &gt;= 0; j-- </span><span class="cov0" title="0">{
                        emptyBins = append(emptyBins, j)
                }</span>
                <span class="cov8" title="1">log.Trace(fmt.Sprintf("%x NNS: %s", addrs[i][:4], LogAddrs(nns)))
                ppmap[common.Bytes2Hex(a)] = &amp;PeerPot{nns, emptyBins}</span>
        }
        <span class="cov8" title="1">return ppmap</span>
}

// saturation returns the lowest proximity order that the bin for that order
// has less than n peers
func (k *Kademlia) saturation(n int) int <span class="cov8" title="1">{
        prev := -1
        k.addrs.EachBin(k.base, pof, 0, func(po, size int, f func(func(val pot.Val, i int) bool) bool) bool </span><span class="cov8" title="1">{
                prev++
                return prev == po &amp;&amp; size &gt;= n
        }</span>)
        <span class="cov8" title="1">depth := k.neighbourhoodDepth()
        if depth &lt; prev </span><span class="cov8" title="1">{
                return depth
        }</span>
        <span class="cov8" title="1">return prev</span>
}

// full returns true if all required bins have connected peers.
// It is used in Healthy function.
func (k *Kademlia) full(emptyBins []int) (full bool) <span class="cov8" title="1">{
        prev := 0
        e := len(emptyBins)
        ok := true
        depth := k.neighbourhoodDepth()
        k.conns.EachBin(k.base, pof, 0, func(po, _ int, _ func(func(val pot.Val, i int) bool) bool) bool </span><span class="cov8" title="1">{
                if prev == depth+1 </span><span class="cov8" title="1">{
                        return true
                }</span>
                <span class="cov8" title="1">for i := prev; i &lt; po; i++ </span><span class="cov8" title="1">{
                        e--
                        if e &lt; 0 </span><span class="cov0" title="0">{
                                ok = false
                                return false
                        }</span>
                        <span class="cov8" title="1">if emptyBins[e] != i </span><span class="cov0" title="0">{
                                log.Trace(fmt.Sprintf("%08x po: %d, i: %d, e: %d, emptybins: %v", k.BaseAddr()[:4], po, i, e, logEmptyBins(emptyBins)))
                                if emptyBins[e] &lt; i </span><span class="cov0" title="0">{
                                        panic("incorrect peerpot")</span>
                                }
                                <span class="cov0" title="0">ok = false
                                return false</span>
                        }
                }
                <span class="cov8" title="1">prev = po + 1
                return true</span>
        })
        <span class="cov8" title="1">if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return e == 0</span>
}

func (k *Kademlia) knowNearestNeighbours(peers [][]byte) bool <span class="cov8" title="1">{
        pm := make(map[string]bool)

        k.eachAddr(nil, 255, func(p OverlayAddr, po int, nn bool) bool </span><span class="cov8" title="1">{
                if !nn </span><span class="cov8" title="1">{
                        return false
                }</span>
                <span class="cov8" title="1">pk := fmt.Sprintf("%x", p.Address())
                pm[pk] = true
                return true</span>
        })
        <span class="cov8" title="1">for _, p := range peers </span><span class="cov8" title="1">{
                pk := fmt.Sprintf("%x", p)
                if !pm[pk] </span><span class="cov0" title="0">{
                        log.Trace(fmt.Sprintf("%08x: known nearest neighbour %s not found", k.BaseAddr()[:4], pk[:8]))
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

func (k *Kademlia) gotNearestNeighbours(peers [][]byte) (got bool, n int, missing [][]byte) <span class="cov8" title="1">{
        pm := make(map[string]bool)

        k.eachConn(nil, 255, func(p OverlayConn, po int, nn bool) bool </span><span class="cov8" title="1">{
                if !nn </span><span class="cov8" title="1">{
                        return false
                }</span>
                <span class="cov8" title="1">pk := fmt.Sprintf("%x", p.Address())
                pm[pk] = true
                return true</span>
        })
        <span class="cov8" title="1">var gots int
        var culprits [][]byte
        for _, p := range peers </span><span class="cov8" title="1">{
                pk := fmt.Sprintf("%x", p)
                if pm[pk] </span><span class="cov8" title="1">{
                        gots++
                }</span> else<span class="cov0" title="0"> {
                        log.Trace(fmt.Sprintf("%08x: ExpNN: %s not found", k.BaseAddr()[:4], pk[:8]))
                        culprits = append(culprits, p)
                }</span>
        }
        <span class="cov8" title="1">return gots == len(peers), gots, culprits</span>
}

// Health state of the Kademlia
type Health struct {
        KnowNN     bool     // whether node knows all its nearest neighbours
        GotNN      bool     // whether node is connected to all its nearest neighbours
        CountNN    int      // amount of nearest neighbors connected to
        CulpritsNN [][]byte // which known NNs are missing
        Full       bool     // whether node has a peer in each kademlia bin (where there is such a peer)
        Hive       string
}

// Healthy reports the health state of the kademlia connectivity
// returns a Health struct
func (k *Kademlia) Healthy(pp *PeerPot) *Health <span class="cov8" title="1">{
        k.lock.RLock()
        defer k.lock.RUnlock()
        gotnn, countnn, culpritsnn := k.gotNearestNeighbours(pp.NNSet)
        knownn := k.knowNearestNeighbours(pp.NNSet)
        full := k.full(pp.EmptyBins)
        log.Trace(fmt.Sprintf("%08x: healthy: knowNNs: %v, gotNNs: %v, full: %v\n", k.BaseAddr()[:4], knownn, gotnn, full))
        return &amp;Health{knownn, gotnn, countnn, culpritsnn, full, k.string()}
}</span>

func logEmptyBins(ebs []int) string <span class="cov0" title="0">{
        var ebss []string
        for _, eb := range ebs </span><span class="cov0" title="0">{
                ebss = append(ebss, fmt.Sprintf("%d", eb))
        }</span>
        <span class="cov0" title="0">return strings.Join(ebss, ", ")</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">// Copyright 2016 The go-ethereum Authors
// This file is part of the go-ethereum library.
//
// The go-ethereum library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// The go-ethereum library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with the go-ethereum library. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package network

import (
        "context"
        "errors"
        "fmt"
        "net"
        "sync"
        "time"

        "github.com/ethereum/go-ethereum/crypto"
        "github.com/ethereum/go-ethereum/p2p"
        "github.com/ethereum/go-ethereum/p2p/discover"
        "github.com/ethereum/go-ethereum/p2p/protocols"
        "github.com/ethereum/go-ethereum/rpc"
        "github.com/ethereum/go-ethereum/swarm/log"
        "github.com/ethereum/go-ethereum/swarm/state"
)

const (
        DefaultNetworkID = 3
        // ProtocolMaxMsgSize maximum allowed message size
        ProtocolMaxMsgSize = 10 * 1024 * 1024
        // timeout for waiting
        bzzHandshakeTimeout = 3000 * time.Millisecond
)

// BzzSpec is the spec of the generic swarm handshake
var BzzSpec = &amp;protocols.Spec{
        Name:       "bzz",
        Version:    4,
        MaxMsgSize: 10 * 1024 * 1024,
        Messages: []interface{}{
                HandshakeMsg{},
        },
}

// DiscoverySpec is the spec for the bzz discovery subprotocols
var DiscoverySpec = &amp;protocols.Spec{
        Name:       "hive",
        Version:    4,
        MaxMsgSize: 10 * 1024 * 1024,
        Messages: []interface{}{
                peersMsg{},
                subPeersMsg{},
        },
}

// Addr interface that peerPool needs
type Addr interface {
        OverlayPeer
        Over() []byte
        Under() []byte
        String() string
        Update(OverlayAddr) OverlayAddr
}

// Peer interface represents an live peer connection
type Peer interface {
        Addr                   // the address of a peer
        Conn                   // the live connection (protocols.Peer)
        LastActive() time.Time // last time active
}

// Conn interface represents an live peer connection
type Conn interface {
        ID() discover.NodeID                                                                  // the key that uniquely identifies the Node for the peerPool
        Handshake(context.Context, interface{}, func(interface{}) error) (interface{}, error) // can send messages
        Send(interface{}) error                                                               // can send messages
        Drop(error)                                                                           // disconnect this peer
        Run(func(interface{}) error) error                                                    // the run function to run a protocol
        Off() OverlayAddr
}

// BzzConfig captures the config params used by the hive
type BzzConfig struct {
        OverlayAddr  []byte // base address of the overlay network
        UnderlayAddr []byte // node's underlay address
        HiveParams   *HiveParams
        NetworkID    uint64
}

// Bzz is the swarm protocol bundle
type Bzz struct {
        *Hive
        NetworkID    uint64
        localAddr    *BzzAddr
        mtx          sync.Mutex
        handshakes   map[discover.NodeID]*HandshakeMsg
        streamerSpec *protocols.Spec
        streamerRun  func(*BzzPeer) error
}

// NewBzz is the swarm protocol constructor
// arguments
// * bzz config
// * overlay driver
// * peer store
func NewBzz(config *BzzConfig, kad Overlay, store state.Store, streamerSpec *protocols.Spec, streamerRun func(*BzzPeer) error) *Bzz <span class="cov8" title="1">{
        return &amp;Bzz{
                Hive:         NewHive(config.HiveParams, kad, store),
                NetworkID:    config.NetworkID,
                localAddr:    &amp;BzzAddr{config.OverlayAddr, config.UnderlayAddr},
                handshakes:   make(map[discover.NodeID]*HandshakeMsg),
                streamerRun:  streamerRun,
                streamerSpec: streamerSpec,
        }
}</span>

// UpdateLocalAddr updates underlayaddress of the running node
func (b *Bzz) UpdateLocalAddr(byteaddr []byte) *BzzAddr <span class="cov0" title="0">{
        b.localAddr = b.localAddr.Update(&amp;BzzAddr{
                UAddr: byteaddr,
                OAddr: b.localAddr.OAddr,
        }).(*BzzAddr)
        return b.localAddr
}</span>

// NodeInfo returns the node's overlay address
func (b *Bzz) NodeInfo() interface{} <span class="cov0" title="0">{
        return b.localAddr.Address()
}</span>

// Protocols return the protocols swarm offers
// Bzz implements the node.Service interface
// * handshake/hive
// * discovery
func (b *Bzz) Protocols() []p2p.Protocol <span class="cov8" title="1">{
        protocol := []p2p.Protocol{
                {
                        Name:     BzzSpec.Name,
                        Version:  BzzSpec.Version,
                        Length:   BzzSpec.Length(),
                        Run:      b.runBzz,
                        NodeInfo: b.NodeInfo,
                },
                {
                        Name:     DiscoverySpec.Name,
                        Version:  DiscoverySpec.Version,
                        Length:   DiscoverySpec.Length(),
                        Run:      b.RunProtocol(DiscoverySpec, b.Hive.Run),
                        NodeInfo: b.Hive.NodeInfo,
                        PeerInfo: b.Hive.PeerInfo,
                },
        }
        if b.streamerSpec != nil &amp;&amp; b.streamerRun != nil </span><span class="cov0" title="0">{
                protocol = append(protocol, p2p.Protocol{
                        Name:    b.streamerSpec.Name,
                        Version: b.streamerSpec.Version,
                        Length:  b.streamerSpec.Length(),
                        Run:     b.RunProtocol(b.streamerSpec, b.streamerRun),
                })
        }</span>
        <span class="cov8" title="1">return protocol</span>
}

// APIs returns the APIs offered by bzz
// * hive
// Bzz implements the node.Service interface
func (b *Bzz) APIs() []rpc.API <span class="cov8" title="1">{
        return []rpc.API{{
                Namespace: "hive",
                Version:   "3.0",
                Service:   b.Hive,
        }}
}</span>

// RunProtocol is a wrapper for swarm subprotocols
// returns a p2p protocol run function that can be assigned to p2p.Protocol#Run field
// arguments:
// * p2p protocol spec
// * run function taking BzzPeer as argument
//   this run function is meant to block for the duration of the protocol session
//   on return the session is terminated and the peer is disconnected
// the protocol waits for the bzz handshake is negotiated
// the overlay address on the BzzPeer is set from the remote handshake
func (b *Bzz) RunProtocol(spec *protocols.Spec, run func(*BzzPeer) error) func(*p2p.Peer, p2p.MsgReadWriter) error <span class="cov8" title="1">{
        return func(p *p2p.Peer, rw p2p.MsgReadWriter) error </span><span class="cov8" title="1">{
                // wait for the bzz protocol to perform the handshake
                handshake, _ := b.GetHandshake(p.ID())
                defer b.removeHandshake(p.ID())
                select </span>{
                case &lt;-handshake.done:</span><span class="cov8" title="1">
                case &lt;-time.After(bzzHandshakeTimeout):<span class="cov0" title="0">
                        return fmt.Errorf("%08x: %s protocol timeout waiting for handshake on %08x", b.BaseAddr()[:4], spec.Name, p.ID().Bytes()[:4])</span>
                }
                <span class="cov8" title="1">if handshake.err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("%08x: %s protocol closed: %v", b.BaseAddr()[:4], spec.Name, handshake.err)
                }</span>
                // the handshake has succeeded so construct the BzzPeer and run the protocol
                <span class="cov8" title="1">peer := &amp;BzzPeer{
                        Peer:       protocols.NewPeer(p, rw, spec),
                        localAddr:  b.localAddr,
                        BzzAddr:    handshake.peerAddr,
                        lastActive: time.Now(),
                }
                return run(peer)</span>
        }
}

// performHandshake implements the negotiation of the bzz handshake
// shared among swarm subprotocols
func (b *Bzz) performHandshake(p *protocols.Peer, handshake *HandshakeMsg) error <span class="cov8" title="1">{
        ctx, cancel := context.WithTimeout(context.Background(), bzzHandshakeTimeout)
        defer func() </span><span class="cov8" title="1">{
                close(handshake.done)
                cancel()
        }</span>()
        <span class="cov8" title="1">rsh, err := p.Handshake(ctx, handshake, b.checkHandshake)
        if err != nil </span><span class="cov8" title="1">{
                handshake.err = err
                return err
        }</span>
        <span class="cov8" title="1">handshake.peerAddr = rsh.(*HandshakeMsg).Addr
        return nil</span>
}

// runBzz is the p2p protocol run function for the bzz base protocol
// that negotiates the bzz handshake
func (b *Bzz) runBzz(p *p2p.Peer, rw p2p.MsgReadWriter) error <span class="cov8" title="1">{
        handshake, _ := b.GetHandshake(p.ID())
        if !&lt;-handshake.init </span><span class="cov0" title="0">{
                return fmt.Errorf("%08x: bzz already started on peer %08x", b.localAddr.Over()[:4], ToOverlayAddr(p.ID().Bytes())[:4])
        }</span>
        <span class="cov8" title="1">close(handshake.init)
        defer b.removeHandshake(p.ID())
        peer := protocols.NewPeer(p, rw, BzzSpec)
        err := b.performHandshake(peer, handshake)
        if err != nil </span><span class="cov8" title="1">{
                log.Warn(fmt.Sprintf("%08x: handshake failed with remote peer %08x: %v", b.localAddr.Over()[:4], ToOverlayAddr(p.ID().Bytes())[:4], err))

                return err
        }</span>
        // fail if we get another handshake
        <span class="cov8" title="1">msg, err := rw.ReadMsg()
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov0" title="0">msg.Discard()
        return errors.New("received multiple handshakes")</span>
}

// BzzPeer is the bzz protocol view of a protocols.Peer (itself an extension of p2p.Peer)
// implements the Peer interface and all interfaces Peer implements: Addr, OverlayPeer
type BzzPeer struct {
        *protocols.Peer           // represents the connection for online peers
        localAddr       *BzzAddr  // local Peers address
        *BzzAddr                  // remote address -&gt; implements Addr interface = protocols.Peer
        lastActive      time.Time // time is updated whenever mutexes are releasing
}

func NewBzzTestPeer(p *protocols.Peer, addr *BzzAddr) *BzzPeer <span class="cov0" title="0">{
        return &amp;BzzPeer{
                Peer:      p,
                localAddr: addr,
                BzzAddr:   NewAddrFromNodeID(p.ID()),
        }
}</span>

// Off returns the overlay peer record for offline persistence
func (p *BzzPeer) Off() OverlayAddr <span class="cov8" title="1">{
        return p.BzzAddr
}</span>

// LastActive returns the time the peer was last active
func (p *BzzPeer) LastActive() time.Time <span class="cov0" title="0">{
        return p.lastActive
}</span>

/*
 Handshake

* Version: 8 byte integer version of the protocol
* NetworkID: 8 byte integer network identifier
* Addr: the address advertised by the node including underlay and overlay connecctions
*/
type HandshakeMsg struct {
        Version   uint64
        NetworkID uint64
        Addr      *BzzAddr

        // peerAddr is the address received in the peer handshake
        peerAddr *BzzAddr

        init chan bool
        done chan struct{}
        err  error
}

// String pretty prints the handshake
func (bh *HandshakeMsg) String() string <span class="cov8" title="1">{
        return fmt.Sprintf("Handshake: Version: %v, NetworkID: %v, Addr: %v", bh.Version, bh.NetworkID, bh.Addr)
}</span>

// Perform initiates the handshake and validates the remote handshake message
func (b *Bzz) checkHandshake(hs interface{}) error <span class="cov8" title="1">{
        rhs := hs.(*HandshakeMsg)
        if rhs.NetworkID != b.NetworkID </span><span class="cov8" title="1">{
                return fmt.Errorf("network id mismatch %d (!= %d)", rhs.NetworkID, b.NetworkID)
        }</span>
        <span class="cov8" title="1">if rhs.Version != uint64(BzzSpec.Version) </span><span class="cov8" title="1">{
                return fmt.Errorf("version mismatch %d (!= %d)", rhs.Version, BzzSpec.Version)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// removeHandshake removes handshake for peer with peerID
// from the bzz handshake store
func (b *Bzz) removeHandshake(peerID discover.NodeID) <span class="cov8" title="1">{
        b.mtx.Lock()
        defer b.mtx.Unlock()
        delete(b.handshakes, peerID)
}</span>

// GetHandshake returns the bzz handhake that the remote peer with peerID sent
func (b *Bzz) GetHandshake(peerID discover.NodeID) (*HandshakeMsg, bool) <span class="cov8" title="1">{
        b.mtx.Lock()
        defer b.mtx.Unlock()
        handshake, found := b.handshakes[peerID]
        if !found </span><span class="cov8" title="1">{
                handshake = &amp;HandshakeMsg{
                        Version:   uint64(BzzSpec.Version),
                        NetworkID: b.NetworkID,
                        Addr:      b.localAddr,
                        init:      make(chan bool, 1),
                        done:      make(chan struct{}),
                }
                // when handhsake is first created for a remote peer
                // it is initialised with the init
                handshake.init &lt;- true
                b.handshakes[peerID] = handshake
        }</span>

        <span class="cov8" title="1">return handshake, found</span>
}

// BzzAddr implements the PeerAddr interface
type BzzAddr struct {
        OAddr []byte
        UAddr []byte
}

// Address implements OverlayPeer interface to be used in Overlay
func (a *BzzAddr) Address() []byte <span class="cov8" title="1">{
        return a.OAddr
}</span>

// Over returns the overlay address
func (a *BzzAddr) Over() []byte <span class="cov8" title="1">{
        return a.OAddr
}</span>

// Under returns the underlay address
func (a *BzzAddr) Under() []byte <span class="cov8" title="1">{
        return a.UAddr
}</span>

// ID returns the nodeID from the underlay enode address
func (a *BzzAddr) ID() discover.NodeID <span class="cov8" title="1">{
        return discover.MustParseNode(string(a.UAddr)).ID
}</span>

// Update updates the underlay address of a peer record
func (a *BzzAddr) Update(na OverlayAddr) OverlayAddr <span class="cov0" title="0">{
        return &amp;BzzAddr{a.OAddr, na.(Addr).Under()}
}</span>

// String pretty prints the address
func (a *BzzAddr) String() string <span class="cov8" title="1">{
        return fmt.Sprintf("%x &lt;%s&gt;", a.OAddr, a.UAddr)
}</span>

// RandomAddr is a utility method generating an address from a public key
func RandomAddr() *BzzAddr <span class="cov8" title="1">{
        key, err := crypto.GenerateKey()
        if err != nil </span><span class="cov0" title="0">{
                panic("unable to generate key")</span>
        }
        <span class="cov8" title="1">pubkey := crypto.FromECDSAPub(&amp;key.PublicKey)
        var id discover.NodeID
        copy(id[:], pubkey[1:])
        return NewAddrFromNodeID(id)</span>
}

// NewNodeIDFromAddr transforms the underlay address to an adapters.NodeID
func NewNodeIDFromAddr(addr Addr) discover.NodeID <span class="cov8" title="1">{
        log.Info(fmt.Sprintf("uaddr=%s", string(addr.Under())))
        node := discover.MustParseNode(string(addr.Under()))
        return node.ID
}</span>

// NewAddrFromNodeID constucts a BzzAddr from a discover.NodeID
// the overlay address is derived as the hash of the nodeID
func NewAddrFromNodeID(id discover.NodeID) *BzzAddr <span class="cov8" title="1">{
        return &amp;BzzAddr{
                OAddr: ToOverlayAddr(id.Bytes()),
                UAddr: []byte(discover.NewNode(id, net.IP{127, 0, 0, 1}, 30303, 30303).String()),
        }
}</span>

// NewAddrFromNodeIDAndPort constucts a BzzAddr from a discover.NodeID and port uint16
// the overlay address is derived as the hash of the nodeID
func NewAddrFromNodeIDAndPort(id discover.NodeID, host net.IP, port uint16) *BzzAddr <span class="cov0" title="0">{
        return &amp;BzzAddr{
                OAddr: ToOverlayAddr(id.Bytes()),
                UAddr: []byte(discover.NewNode(id, host, port, port).String()),
        }
}</span>

// ToOverlayAddr creates an overlayaddress from a byte slice
func ToOverlayAddr(id []byte) []byte <span class="cov8" title="1">{
        return crypto.Keccak256(id)
}</span>
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
